{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final Project For Kaggle (cleaned version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lazy loading data\n",
    "class LazyLoadDataset(Dataset):\n",
    "    def __init__(self, path, train = True, transform = None):\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        path = path + ('train/' if train else 'test/')\n",
    "\n",
    "        self.pathX = path + 'X/'\n",
    "        self.pathY = path + 'Y/'\n",
    "\n",
    "        self.data = os.listdir(self.pathX)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        f = self.data[index]\n",
    "\n",
    "        # X\n",
    "        # read rgb images\n",
    "        img0 = cv2.imread(self.pathX + f + '/rgb/0.png')\n",
    "        img1 = cv2.imread(self.pathX + f + '/rgb/1.png')\n",
    "        img2 = cv2.imread(self.pathX + f + '/rgb/2.png')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        \n",
    "        # read depth\n",
    "        depth = np.load(self.pathX + f + '/depth.npy') / 1000\n",
    "\n",
    "        #read field id\n",
    "        field_id = pkl.load(open(self.pathX + f + '/field_id.pkl', 'rb'))\n",
    "\n",
    "        # Y\n",
    "        if self.train:\n",
    "            Y = np.load(self.pathY + f + '.npy')\n",
    "\n",
    "            return (img0, img1, img2, depth, field_id), Y\n",
    "        else:\n",
    "            return (img0, img1, img2, depth, field_id)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean and Standard Deviation for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std: \n",
      " tensor([0.4851, 0.4623, 0.4356]) tensor([0.2195, 0.2181, 0.2339])\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "\n",
    "# dataset = LazyLoadDataset('./lazydata/', transform = transform)\n",
    "# train_dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "\n",
    "# def get_mean_std(loader):\n",
    "#     (img0, img1, img2, depth, field_id), Y = next(iter(loader))\n",
    "#     img0_mean = img0.mean([0,2,3])\n",
    "#     img0_std = img0.std([0,2,3])\n",
    "#     img1_mean = img1.mean([0,2,3])\n",
    "#     img1_std = img1.std([0,2,3])\n",
    "#     img2_mean = img2.mean([0,2,3])\n",
    "#     img2_std = img2.std([0,2,3])\n",
    "#     mean, std = (img0_mean + img1_mean + img2_mean) / 3, (img0_std + img1_std + img2_std) / 3\n",
    "#     return mean, std\n",
    "\n",
    "# mean, std = get_mean_std(train_dataloader)\n",
    "# print(\"mean and std: \\n\", mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calculated mean and std (save running time)\n",
    "mean = torch.Tensor([0.4851, 0.4623, 0.4356])\n",
    "std = torch.Tensor([0.2195, 0.2181, 0.2339])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_with_normalization = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std),])\n",
    "dataset = LazyLoadDataset('./lazydata/', transform = transform_with_normalization)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture (Slightly modified from AlexNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, conv_feature, fc_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(conv_feature * 6 * 6, fc_feature)\n",
    "        self.fc2 = nn.Linear(fc_feature, fc_feature)\n",
    "        self.fc3 = nn.Linear(fc_feature, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        epoch (int): current epoch\n",
    "        model (nn.Module): model to train\n",
    "        optimizer (torch.optim): optimizer to use\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, ((img0, img1, img2, depth, field_id), target) in enumerate(train_dataloader):\n",
    "        # send three images and depth to device\n",
    "        data = torch.cat((img0, img1, img2, depth), dim=1).to(device)\n",
    "        # send target to device\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        # mseloss\n",
    "        loss = nn.MSELoss()(output.float(), target.float() * 1000.0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
    "            100. * batch_idx / len(train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "# number of feature maps\n",
    "conv_features = 256\n",
    "# number of input channels\n",
    "input_channels = 12\n",
    "fc_features = 4096\n",
    "output_size = 12\n",
    "\n",
    "# optimal lr\n",
    "# lr = 0.0001\n",
    "\n",
    "# test lr\n",
    "lr = 0.0001\n",
    "\n",
    "model_cnn = CNN(input_channels, conv_features, fc_features, output_size) # create CNN model\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr = lr) # create optimizer\n",
    "\n",
    "# lr scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)  \n",
    "\n",
    "for epoch in range(0, 20):\n",
    "    train(epoch, model_cnn, optimizer)\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LazyLoadDataset('./lazydata/', train = False, transform = transform_with_normalization)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64 * 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict(model):\n",
    "    outfile = 'submission.csv'\n",
    "    output_file = open(outfile, 'w')\n",
    "    titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
    "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
    "    \n",
    "    model.eval()\n",
    "    pred = []\n",
    "    file_ids = []\n",
    "\n",
    "    for i, ((img0, img1, img2, depth, field_id)) in enumerate(test_dataloader):\n",
    "        data = torch.cat((img0, img1, img2, depth), dim=1).to(device)\n",
    "        output = model(data)\n",
    "        pred.append(output.cpu().detach().numpy())\n",
    "        file_ids.extend(field_id)\n",
    "    \n",
    "    pred = np.concatenate(pred) / 1000.0\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(pred)], axis = 1, names = titles)\n",
    "    df.columns = titles\n",
    "    df.to_csv(outfile, index = False)\n",
    "    print(\"Written to csv file {}\".format(outfile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
